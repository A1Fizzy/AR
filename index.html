<!DOCTYPE html>
<html>
<head>
    <title>AR Gesture Control</title>
    <style>
        body { margin: 0; overflow: hidden; }
        canvas { display: block; }
    </style>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection"></script>

    <script>
        let scene, camera, renderer, object;
        let detector;
        let videoElement;

        async function init() {
            // Инициализация Three.js
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.xr.enabled = true;
            document.body.appendChild(renderer.domElement);

            // Настройка WebXR
            renderer.xr.addEventListener('sessionstart', async () => {
                videoElement = document.createElement('video');
                navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                    videoElement.srcObject = stream;
                    videoElement.play();
                });
            });

            // Добавление 3D-объекта
            const geometry = new THREE.BoxGeometry(1, 1, 1);
            const material = new THREE.MeshBasicMaterial({ color: 0x00ff00 });
            object = new THREE.Mesh(geometry, material);
            object.position.set(0, 0, -2);
            scene.add(object);

            // Инициализация детектора жестов
            detector = await handPoseDetection.createDetector(
                handPoseDetection.SupportedModels.MediaPipeHands,
                {
                    runtime: 'mediapipe',
                    modelType: 'full',
                    maxHands: 1,
                    solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/hands'
                }
            );

            // Запуск AR сессии
            const session = await navigator.xr.requestSession('immersive-ar');
            renderer.xr.setSession(session);

            animate();
        }

        async function detectGestures() {
            if (!videoElement) return;

            const hands = await detector.estimateHands(videoElement);
            if (hands.length > 0) {
                const hand = hands[0];
                // Жест масштабирования (пинч)
                const thumbTip = hand.keypoints.find(k => k.name === 'thumb_tip');
                const indexTip = hand.keypoints.find(k => k.name === 'index_finger_tip');
                const distance = Math.hypot(
                    thumbTip.x - indexTip.x,
                    thumbTip.y - indexTip.y
                );
                
                if (distance < 40) { // Пороговое значение для пинча
                    const scale = 1 + (40 - distance) * 0.01;
                    object.scale.set(scale, scale, scale);
                }

                // Вращение по ориентации ладони
                const wrist = hand.keypoints.find(k => k.name === 'wrist');
                const middleBase = hand.keypoints.find(k => k.name === 'middle_finger_mcp');
                const angle = Math.atan2(
                    middleBase.y - wrist.y,
                    middleBase.x - wrist.x
                );
                object.rotation.y = angle;
            }
        }

        function animate() {
            renderer.setAnimationLoop(() => {
                detectGestures();
                renderer.render(scene, camera);
            });
        }

        init();
    </script>
</body>
</html>
